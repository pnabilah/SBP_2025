{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "563fefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output from Dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c1b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        x          y\n",
      "0      34   0.000000\n",
      "1     -53 -22.450000\n",
      "2     -73  -2.348020\n",
      "3     -97  -2.196466\n",
      "4      98  53.771690\n",
      "...    ..        ...\n",
      "29997  48   3.301395\n",
      "29998  42  -3.815961\n",
      "29999  90   9.964261\n",
      "30000 -77 -46.240029\n",
      "30001 -71   5.350467\n",
      "\n",
      "[30002 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate input - output data\n",
    "\n",
    "def generate_xy(num_samples=10):\n",
    "    # x = np.random.uniform(-1, 1, num_samples) # Input random\n",
    "    x = np.random.randint(-100, 100, num_samples) # Input random\n",
    "    y = np.zeros(num_samples)\n",
    "    \n",
    "    y[0] = 0   # Inisialisasi\n",
    "    \n",
    "    for k in range(1, num_samples):\n",
    "        y[k] = 1 / (1 + y[k-1]**2) + 0.25*x[k] - 0.3*x[k-1]\n",
    "    \n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "    return df\n",
    "\n",
    "df = generate_xy(30002)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a7fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x(t)  x(t-1)  x(t-2)     y(t-1)     y(t-2)       y(t)\n",
      "0   -73   -53.0    34.0 -22.450000   0.000000  -2.348020\n",
      "1   -97   -73.0   -53.0  -2.348020 -22.450000  -2.196466\n",
      "2    98   -97.0   -73.0  -2.196466  -2.348020  53.771690\n",
      "3    56    98.0   -97.0  53.771690  -2.196466 -15.399654\n",
      "4   -44    56.0    98.0 -15.399654  53.771690 -27.795801\n",
      "(30000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset from input output\n",
    "df_lagged = pd.DataFrame({\n",
    "    \"x(t)\"   : df[\"x\"],\n",
    "    \"x(t-1)\" : df[\"x\"].shift(1),\n",
    "    \"x(t-2)\" : df[\"x\"].shift(2),\n",
    "    \"y(t-1)\" : df[\"y\"].shift(1),\n",
    "    \"y(t-2)\" : df[\"y\"].shift(2),\n",
    "    \"y(t)\"   : df[\"y\"]   # target\n",
    "})  # 3 lagged inputs and 2 lagged outputs\n",
    "\n",
    "df_lagged = df_lagged.dropna().reset_index(drop=True) # drop NaN values from first lagged rows\n",
    "\n",
    "# Check the dataset\n",
    "print(df_lagged.head())\n",
    "print(df_lagged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6db913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.001, seed=42):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # struktur\n",
    "        self.NI = input_size\n",
    "        self.NH = hidden_size\n",
    "        self.NO = output_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # inisialisasi bobot\n",
    "        self.v = np.random.rand(self.NI, self.NH)   # input → hidden\n",
    "        self.vb = np.random.rand(self.NH)           # bias hidden\n",
    "        self.w = np.random.rand(self.NH, self.NO)   # hidden → output\n",
    "        self.wb = np.random.rand(self.NO)           # bias output\n",
    "\n",
    "    # --- Activation functions ---\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        s = self.sigmoid(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    # --- Feedforward ---\n",
    "    def feedforward(self, x):\n",
    "        # hidden\n",
    "        self.z_in = np.dot(x, self.v) + self.vb\n",
    "        self.z = self.sigmoid(self.z_in)\n",
    "\n",
    "        # output (pakai linear, bisa diganti sigmoid/tanh kalau mau)\n",
    "        self.y_in = np.dot(self.z, self.w) + self.wb\n",
    "        self.y = self.y_in  \n",
    "\n",
    "        return self.y\n",
    "\n",
    "    # --- Backpropagation ---\n",
    "    def backpropagation(self, x, t):\n",
    "        # error output\n",
    "        delta_y = (t - self.y)\n",
    "        del_w = self.lr * np.outer(self.z, delta_y)\n",
    "        del_wb = self.lr * delta_y\n",
    "\n",
    "        # error hidden\n",
    "        delta_zin = np.dot(delta_y, self.w.T)\n",
    "        delta_z = delta_zin * self.z * (1 - self.z)  # sigmoid derivative\n",
    "        del_v = self.lr * np.outer(x, delta_z)\n",
    "        del_vb = self.lr * delta_z\n",
    "\n",
    "        # update bobot\n",
    "        self.w += del_w\n",
    "        self.wb += del_wb\n",
    "        self.v += del_v\n",
    "        self.vb += del_vb\n",
    "\n",
    "        return np.mean(delta_y**2)   # return MSE\n",
    "\n",
    "    # --- Training loop ---\n",
    "    def fit(self, X, T, epochs=1000, tol=0.01):\n",
    "        history = []\n",
    "        for epoch in range(epochs):\n",
    "            mse = 0\n",
    "            for x, t in zip(X, T):\n",
    "                self.feedforward(x)\n",
    "                mse += self.backpropagation(x, t)\n",
    "            mse /= len(X)\n",
    "            history.append(mse)\n",
    "            if mse < tol:\n",
    "                print(f\"Training stopped at epoch {epoch}, MSE={mse:.6f}\")\n",
    "                break\n",
    "        return history\n",
    "\n",
    "    # --- Prediction ---\n",
    "    def predict(self, X):\n",
    "        outputs = []\n",
    "        for x in X:\n",
    "            outputs.append(self.feedforward(x))\n",
    "        return np.array(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cca3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.001, seed=42):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # struktur\n",
    "        self.NI = input_size\n",
    "        self.NH = hidden_size\n",
    "        self.NO = output_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # inisialisasi bobot\n",
    "        self.v = np.random.rand(self.NI, self.NH)   # input → hidden\n",
    "        self.vb = np.random.rand(self.NH)           # bias hidden\n",
    "        self.w = np.random.rand(self.NH, self.NO)   # hidden → output\n",
    "        self.wb = np.random.rand(self.NO)           # bias output\n",
    "\n",
    "    # --- Activation functions ---\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        s = self.sigmoid(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    # --- Feedforward ---\n",
    "    def feedforward(self, x):\n",
    "        # hidden\n",
    "        self.z_in = np.dot(x, self.v) + self.vb\n",
    "        self.z = self.sigmoid(self.z_in)\n",
    "\n",
    "        # output (pakai linear, bisa diganti sigmoid/tanh kalau mau)\n",
    "        self.y_in = np.dot(self.z, self.w) + self.wb\n",
    "        self.y = self.y_in  \n",
    "\n",
    "        return self.y\n",
    "\n",
    "    # --- Backpropagation ---\n",
    "    def backpropagation(self, x, t):\n",
    "        # error output\n",
    "        delta_y = (t - self.y)\n",
    "        del_w = self.lr * np.outer(self.z, delta_y)\n",
    "        del_wb = self.lr * delta_y\n",
    "\n",
    "        # error hidden\n",
    "        delta_zin = np.dot(delta_y, self.w.T)\n",
    "        delta_z = delta_zin * self.z * (1 - self.z)  # sigmoid derivative\n",
    "        del_v = self.lr * np.outer(x, delta_z)\n",
    "        del_vb = self.lr * delta_z\n",
    "\n",
    "        # update bobot\n",
    "        self.w += del_w\n",
    "        self.wb += del_wb\n",
    "        self.v += del_v\n",
    "        self.vb += del_vb\n",
    "\n",
    "        return np.mean(delta_y**2)   # return MSE\n",
    "\n",
    "    # --- Training loop with validation ---\n",
    "    def fit(self, X_train, T_train, X_val=None, T_val=None,\n",
    "            epochs=1000, tol=0.01, patience=20):\n",
    "        history = {\"train_loss\": [], \"val_loss\": []}\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_ctr = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            mse = 0\n",
    "            # training\n",
    "            for x, t in zip(X_train, T_train):\n",
    "                self.feedforward(x)\n",
    "                mse += self.backpropagation(x, t)\n",
    "            mse /= len(X_train)\n",
    "            history[\"train_loss\"].append(mse)\n",
    "\n",
    "            # validation (no weight update)\n",
    "            if X_val is not None and T_val is not None:\n",
    "                val_loss = 0\n",
    "                for x, t in zip(X_val, T_val):\n",
    "                    y_pred = self.feedforward(x)\n",
    "                    val_loss += np.mean((t - y_pred)**2)\n",
    "                val_loss /= len(X_val)\n",
    "                history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "                # early stopping check\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_ctr = 0\n",
    "                else:\n",
    "                    patience_ctr += 1\n",
    "                    if patience_ctr >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch}, val_loss={val_loss:.6f}\")\n",
    "                        break\n",
    "\n",
    "            # tolerance check (on training loss)\n",
    "            if mse < tol:\n",
    "                print(f\"Training stopped at epoch {epoch}, train_loss={mse:.6f}\")\n",
    "                break\n",
    "\n",
    "        return history\n",
    "\n",
    "    # --- Prediction ---\n",
    "    def predict(self, X):\n",
    "        outputs = []\n",
    "        for x in X:\n",
    "            outputs.append(self.feedforward(x))\n",
    "        return np.array(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61f2f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5) (30000, 1)\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "X = df_lagged[[\"x(t)\", \"x(t-1)\", \"x(t-2)\", \"y(t-1)\", \"y(t-2)\"]].values   # 100 sampel, input size=6\n",
    "T = df_lagged[[\"y(t)\"]].values    # target\n",
    "\n",
    "# check size of dataset\n",
    "print(X.shape, T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, T, train=0.7, val=0.15, test=0.15, seed=None):\n",
    "    \"\"\"\n",
    "    Membagi dataset menjadi train, validation, dan test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Fitur/input dataset.\n",
    "    T : np.ndarray\n",
    "        Target/label dataset.\n",
    "    train, val, test : float\n",
    "        Proporsi pembagian dataset (jumlahnya harus 1).\n",
    "    seed : int or None\n",
    "        Random seed untuk hasil konsisten.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (X_train, T_train, X_val, T_val, X_test, T_test)\n",
    "    \"\"\"\n",
    "    assert abs(train + val + test - 1.0) < 1e-8, \"Proporsi harus berjumlah 1\"\n",
    "\n",
    "    n_total = len(X)\n",
    "    indices = np.arange(n_total)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    n_train = int(train * n_total)\n",
    "    n_val   = int(val * n_total)\n",
    "    n_test  = n_total - n_train - n_val\n",
    "\n",
    "    train_idx = indices[:n_train]\n",
    "    val_idx   = indices[n_train:n_train+n_val]\n",
    "    test_idx  = indices[n_train+n_val:]\n",
    "\n",
    "    return (X[train_idx], T[train_idx],\n",
    "            X[val_idx],  T[val_idx],\n",
    "            X[test_idx], T[test_idx])\n",
    "\n",
    "\n",
    "X_train, T_train, X_val, T_val, X_test, T_test = split_dataset(X, T, 0.7, 0.15, 0.15, seed=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, T_train.shape)\n",
    "print(\"Val  :\", X_val.shape, T_val.shape)\n",
    "print(\"Test :\", X_test.shape, T_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72967d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (15000, 5) (15000, 1)\n",
      "Val  : (10000, 5) (10000, 1)\n",
      "Test : (10000, 5) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "def split_dataset_seq(X, T):\n",
    "    \"\"\"\n",
    "    Membagi dataset 30.000 sample secara berurutan:\n",
    "    - Train: 15.000 pertama\n",
    "    - Val: 5.000 terakhir dari train + 5.000 setelah train\n",
    "    - Test: 10.000 terakhir\n",
    "    \"\"\"\n",
    "    assert len(X) == len(T), \"Jumlah X dan T harus sama\"\n",
    "    assert len(X) == 30000, \"Dataset harus 30.000 sample sesuai aturan\"\n",
    "\n",
    "    # Train 15.000 pertama\n",
    "    X_train = X[:15000]\n",
    "    T_train = T[:15000]\n",
    "\n",
    "    # Validation = 5000 terakhir train + 5000 setelah train\n",
    "    X_val = np.concatenate([X[10000:15000], X[15000:20000]])\n",
    "    T_val = np.concatenate([T[10000:15000], T[15000:20000]])\n",
    "\n",
    "    # Test = 10000 terakhir\n",
    "    X_test = X[20000:30000]\n",
    "    T_test = T[20000:30000]\n",
    "\n",
    "    return X_train, T_train, X_val, T_val, X_test, T_test\n",
    "\n",
    "X_train, T_train, X_val, T_val, X_test, T_test = split_dataset_seq(X, T)\n",
    "print(\"Train:\", X_train.shape, T_train.shape)\n",
    "print(\"Val  :\", X_val.shape, T_val.shape)\n",
    "print(\"Test :\", X_test.shape, T_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f155627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\putin\\AppData\\Local\\Temp\\ipykernel_23176\\237202302.py:19: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m BPNN(input_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast train loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast val loss  :\u001b[39m\u001b[38;5;124m\"\u001b[39m, history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[19], line 78\u001b[0m, in \u001b[0;36mBPNN.fit\u001b[1;34m(self, X_train, T_train, X_val, T_val, epochs, tol, patience)\u001b[0m\n\u001b[0;32m     76\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_val, T_val):\n\u001b[1;32m---> 78\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeedforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((t \u001b[38;5;241m-\u001b[39m y_pred)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     80\u001b[0m val_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_val)\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mBPNN.feedforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeedforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# hidden\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_in \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvb\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_in)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# output (pakai linear, bisa diganti sigmoid/tanh kalau mau)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# buat model\n",
    "model = BPNN(input_size=X_train.shape[1], hidden_size=128, output_size=1, lr=0.001)\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, T_train, X_val, T_val, epochs=1000, tol=1e-3, patience=20)\n",
    "\n",
    "print(\"Last train loss:\", history[\"train_loss\"][-1])\n",
    "print(\"Last val loss  :\", history[\"val_loss\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
